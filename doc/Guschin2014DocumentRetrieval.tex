\documentclass[12pt,twoside]{article}

\usepackage{jmlda}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{subfig}
\bibliographystyle{unsrt}


\title
    [Последовательное порождение существенно нелинейных моделей] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Последовательное порождение существенно нелинейных моделей в задачах ранжирования документов}
\author
    [Гущин~А.\,Е.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Гущин~А.\,Е.} % основной список авторов, выводимый в оглавление
\thanks
    {Численные методы обучения по прецедентам (практика, В.В. Стрижов)/Группа 174, весна 2014}
\email
    {1aguschin@gmail.com}
\organization
    {Московский физико-технический институт}
\abstract
    {В работе исследуется алгоритм поиска функций ранжирования, являюшихся суперпозициями элементарных математических функций. Обычно все модели, использующиеся для ранжирования документов, имеют две независимые переменные~--- частоту терма и частоту документа. В работе предлагается осуществить генерацию функций от этих переменных с помощью генетического программирования. Полученные функции протестированы на различных тестовых коллекциях. Приводится сравнение эффективности ранжирования функций, полученных в данной работе, с классическими функциями.

\bigskip
\textbf{Ключевые слова}: \emph {информационный поиск, ранжирование документов, генетическое программирование}.}

\begin{document}
\maketitle

\section{Введение}

Задача ранжирования документов является одной из основных задач информационного поиска. Она заключается в поиске функции, наилучшим образом определяющей порядок документов в коллекции соответственно некоторому запросу.

С начала исследования информационного поиска разработано множество методов решения этой задачи, таких как vector space model \cite{salton1983introduction}, the language model \cite{ponte1998language}, BM25 \cite{robertson2004simple}, и, более поздних, таких как HMM \cite{metzler2005markov}, DFR \cite{Goswami2014} и information-based models \cite{clinchant2010information}. Все вышеперечисленные методы были разработаны в соответствии с теоретическими представлениями в области информационного поиска. Однако, так как не все методы легко объяснимы теоретически, при таком подходе к решению задачи ранжирования документов существует риск упустить некоторые более эффективные ранжирующие функции.

Ограничения этого подхода привели к исследованию пространства ранжирующих функций более систематически, несмотря на то, что такой подход ограничен сложностью пространства (его бесконечной размерностью и тем, что оно потенциально содержит все реальные функции). Первые попытки были основаны на использовании генетического программирования и генетических алгоритмов, для того, чтобы исследовать пространство функций ранжирования стохастически [12,16,6]. В работе [9] генетическое программирование было использовано для того, чтобы отыскать как оптимальные ранжирующие функции для отдельных запросов, так и одну оптимальную функцию для нескольких запросов. Однако, такой подход не лишен недостатков. Решения, сгенерированные данными алгоритмами часто сложно анализировать. Кроме того, генетическому программированию свойственно "раздувание кода", когда практически все генетические алгоритмы имеют тенденцию производить всё более и более сложные функции с течением итераций. Таким образом, существует риск пропустить простые функции высокого качества.

Позднее исследователи сосредоточились на нахождении функций ранжирования как линейных комбинаций уже проверенных функций, параметры которых настраиваются с помощью тренировочных коллекций. В соответствии с этим методом были предложены различные методы "обучения ранжированию"  \cite{liu2009learning} : поточечный подход (например, \cite{crammer2001pranking}), попарный подход (например, \cite{cohen2011learning, freund2003efficient, joachims1999making}), или списочный подход (например, \cite{valizadegan2009learning}).

Несмотря на свою эффективность, последние методы имеют два ограничения: во-первых, обычно они представляют функцию ранжирования как функцию строго определенного вида (например, линейную или полиномиальную), во-вторых, им требуется тестовый набор данных для того, чтобы настроить параметры модели.

Наконец, в работе \cite{Goswami2014} предлагается решение описанных недостатков методом построения суперпозиций с помощью грамматики и словаря базисных функций. Однако, в связи со вычислительной сложностью генерации большого количества суперпозиций авторам пришлось ограничиться суперпозициями, состоящих менее чем из восьми функций и переменных.

В настоящей работе для порождения ранжирующих функций предлагается использование библиотеки индуктивного порождения нелинейных моделей Multivariate Regression Composer (MVR) для Matlab. Использованием генетического программирования предполагается исследовать функции, которые невозможно было проверить в работе \cite{Goswami2014}. С другой стороны, возникновение функций избыточной сложности, связанное с применением генетического программирования в MVR предлагается решить с помощью добавления штрафа за сложность суперпозиции. Генетическое программирование также не накладывает ограничений на вид возможных функций ранжирования.

%В \cite{Rudoy2013Generation} исследованы индуктивные алгоритмы порождения допустимых существенно нелинейных суперпозиций. Предложен переборный алгоритм, решающий проблему порождения слишком сложных суперпозиций введением дополнительного штрафа за сложность. Описан адаптивный стохастический алгоритм индуктивного порождения существенно нелинейных моделей, выбирающий менее точные, но более простые модели, что позволяет избежать переобучения и выполнить простейший отбор признаков.

\section{Постановка задачи}

Пусть дана выборка:

$$\mathfrak{S} = \{\mathfrak{D}_j|j=\{1,\ldots,K\}\},$$

$$\mathfrak{D}_j = \{({\mathbf{x}_i},y_i)|i=\{1,\ldots,N_j\}, ~{\mathbf{x}_i} \in \mathbb{X}\subset\mathbb{R}^n,~y_i \in \mathbb{Y} \subset \mathbb{R}\},$$

где $K$ - число выборок; $N_j$ - число элементов в выборке $j$; $\mathbf{x}_i$ - $i$-ый элемент выборки, обладающий $n$ признаками; $\mathbb{X}$ - пространство значений вектора признаков, лежащее в $\mathbb{R}^n$; $\mathbb{Y}$ - множество значений зависимой переменной.%; $\mathbb{Z}$ - множество значений номеров групп, на которые разбиты пары $({\mathbf{x}_i},y_i)$.

Требуется найти оптимальные в смысле максимизации некоторого функционала качества параметрические функции $f : \Omega \times \mathbb{X} \longmapsto \mathbb{R}$ вида

\begin{equation}
f(\mathbf{x}) = \sum_{q=1}^{n} \omega_q\ {x}_q + \sum_{q=n+1}^{n+m}~\omega_q\varphi_q(\mathbf{x}),~f(\mathbf{x}) \in \mathcal{H}
\end{equation}

где $\mathbf{w} \in \Omega$ ~--- вектор параметров модели, а функции $\varphi_q(\mathbf{x}) \in \mathcal{F}$ порождаются как суперпозиция базисных функций $g \in \mathcal{G}$, то есть как нелинейная суперпозиция признаков. Порождаемую суперпозицию можно представить как ориентированное дерево (связанный ациклический граф), вершина $V_i$ которого представляет собой функцию $g_i \in \mathcal{G}$, где число дочерних вершин $V_i$ равно арности функции $g_i$, а лист $V_j$ представляет признак $x_j$ либо числовой параметр $w_j$.

Порождаемая суперпозиция должна быть допустимой, то есть суперпозиция $\varphi_q(\mathbf{x})$ должна быть определена для любых $\mathbf{x} \in \mathbb{R}^n$. Таким образом, для функции $g(g_1(\mathbf{x}),...,g_k(\mathbf{x}))$ область значений функций $g_1(\mathbf{x}),...,g_k(\mathbf{x})$ должна быть подмножеством области допустимых значений функции $g(x_1,...,x_k)$.

Элементы множества $\mathcal{F}=\{\varphi_q(\mathbf{x})\}$ могут быть порождены индуктивно как суперпозиции функций из некоторого заданного набора элементарных функций $\mathcal{G}=\{g_1, \dots, g_m\}$.

Таким образом, задача состоит в том, чтоб найти функции $f_{\hat{r}} \in \mathcal{H}$, имеющие максимальное значение некоторого функционала качества Q:

\begin{equation}
\label{eq:r_opt}
\hat{r} = \argmax_{r \in \mathbb{N}} (Q(f_r|\hat{\boldsymbol\omega}_r, \mathfrak{D})),
\end{equation}

где $\hat{\boldsymbol\omega}_r$ - оптимальный набор параметров модели $f_r$:
\begin{equation}
\label{eq:w_opt}
\hat{\boldsymbol\omega}_r = \argmax_{\boldsymbol\omega \in \Omega} (Q(\boldsymbol\omega|~f_r, \mathfrak{D})),
\end{equation}

Рассмотрим подробнее используемый функционал качества Q. Пусть некоторая коллекция документов $\{x_i\}\in \mathbb{X}$ была ранжирована в соответствии с некоторой функцией и было выбрано $\textbf{p}$ наиболее релевантных документов. Эти \textbf{p} документов были также оценены экспертом, который выставил для i-того документа оценку $y_i$ от 0 до 3: нерелевантный документ - 0, полностью релевантный - 3, для промежуточных оценок - 1 и 2. Для оценки качества ранжирующей функции воспользуемся DCG (Discounted cumulative gain):

\begin{equation}
\label{eq:DFG_error}
\mathrm{DCG_{p}} = \sum_{i=1}^{p} \frac{ 2^{y_{i}} - 1 }{ \log_{2}(i+1)},
\end{equation}

Количество выбранных документов \textbf{p} может отличаться для различных запросов. Для того, чтобы оценить ранжирующую функцию на различных запросах, необходимо нормализовать DCG. Для этого обозначим $\mathrm{IDCG_{p}}$ значение, которое принимает $\mathrm{DCG_{p}}$ на идеально ранжированной выборке. Тогда нормализованная DCG:

\begin{equation}
\label{eq:nDCG_error}
\mathrm{nDCG_{p} = \frac{DCG_{p}}{IDCG_{p}}},
\end{equation}

\section{Алгоритм решения задачи ранжирования с выбором нелинейных признаков}

\subsection{Выбор признаков среди $\{ x_1,...,x_n,\varphi_1,...,\varphi_m \}$ и оценка параметра $\mathbf{w}$}

Выбор наилучшей модели осуществим относительно среднеквадратичной ошибки
\[
S(\mathbf{w}) = \sum \limits_{i = 1} ^k (y_i - f(\mathbf{w},\mathbf{x}_i))^2,
\]
проведя для этого отбор наиболее информативных признаков.
Искомая модель имеет вид $f^*(\mathbf{x}) = \varphi(\mathbf{w}^*,\mathbf{x})$, где параметры модели $\mathbf{w}^*$ должны доставлять минимум функции:
\[
\mathbf{w}^* = \argmin\limits_{\mathbf{w} \in \mathbb{R}^n} S(\mathbf{w} | X^{\ell}, \varphi_F),
\]
где $X^{\ell}$~--- обучающая выборка.
Таким образом, необходимо определить множество $F \subseteq I$, где $I = \{ x_1,...,x_n,\varphi_1,...,\varphi_m \}$, которое доставляло бы минимум функции:
\[
F^* = \argmin\limits_{F \subseteq I} S(\varphi_{F} | \mathbf{w}^*, X^C),
\]
где $X^C$ --- контрольная выборка, $\varphi_F$~--- модель~$\varphi$, включающая только столбцы из множества~$F$.

Отбор признаков предлагается провести методом последовательного добавления признаков, и последующего поиска $F^*$.

На этапе добавления очередного признака находим признак $i^*$:
\[
i^* = \argmin\limits_{i \in I \backslash F_{k-1}} S(\mathbf{w} | X^{\ell}, \varphi_{F_{k - 1} \cup \{ i \}})
\]
и добавляем найденный признак $F_k = F_{k-1} \cup {i^*}$.

После окончания работы алгоритма (то есть после включения всех признаков в модель), находим искомое множество $F^*$ среди $\{F_i\}_{i \in I}$ и соответствующую этому множеству модель $f^*(\mathbf{x})$.

\subsection{Порождение нового признака $\varphi_q$}

Алгоритм порождения нового признака $\varphi_q$:

\begin{enumerate}

\item Для порождения нового признака воспользуемся множеством признаков $F^*$. Построим функционал качества (5) на обучающей выборке $X^{\ell}$.

\item Сгенерируем случайные суперпозиции $\{\varphi_q(X)\}$ и добавим их к уже имеющимся.

\item Произведем скрещивание и мутацию моделей $\{\varphi_q(X)\}$.

\begin{enumerate}
\item Скрещивание двух моделей происходит с помощью обмена случайно выбранного поддеревьева первой модели на случайно выбранное поддерево второй модели.
\item Мутация моделей происходит путём замены случайно выбранной вершины дерева модели на новую случайно сгенерированную модель.
\end{enumerate}

\item Настроим параметры $\omega_q$ моделей $\{\varphi_q(X)\}$ на $X^{\ell}$.

\item Построим функционал качества (5) на контрольной выборке $X^C$. Выберем фиксированное количество моделей, имеющих наибольшее значение функционала качества на $X^C$.

\item Если не достигнуто ни требуемое качество на $X^C$, ни максимальное число итераций, перейдем на следующую итерацию к пункту 2.

\item Выберем признак, имеющий наилучшее качество на $X^C$.
\end{enumerate}

\section{Вычислительный эксперимент}

Целью вычислительного эксперимента является генерация функций ранжирования и проверка их качества. Функция ранжирования коллекции документов является суперпозицией элементарных унарных (логарифм, экспонента, квадратный корень) и бинарных (сложение, вычитание, умножение, деление, степенная функция) функций.

В качестве средства генерации была взята библиотека MVR

(http://sourceforge.net/projects/mvr/), использующая генетические алгоритмы. В качестве функционала качества была взята nDCG. Проверка качества осуществлялась при нахождении nDCG на тестовой выборке, не использовавшейся на этапе генерации функций.

В качестве данных используются реальные таблицы оценок, предоставленные Яндексом (http://imat2009.yandex.ru/academic/mathematic/2009/datasets).  Таблицы содержат уже посчитанные и нормализованные признаки пар «запрос-документ», а также оценки релевантности, сделанные асессорами (оценщиками качества поиска) Яндекса. Таблицы не содержат оригинальных запросов и ссылок на оригинальные документы, не описана семантика признаков (признаки просто пронумерованы). Примеры признаков, участвующих в таблице, – частота слова в документе, частота документов с данным словом в коллекции (tf*idf), длина запроса в словах.

Для проведения вычислительного эксперимента было выбрано 4 информативных признака.

Каждая строка файлов данных соответствует паре «запрос-документ». Все признаки либо бинарные – принимают значения из {0, 1}, либо непрерывные. Значения непрерывных признаков нормированы на интервал [0, 1]. Каждой паре «запрос-документ» соответствуют значения 245 признаков. Если значение признака равно 0, то он опускается. В комментариях в конце каждой строки указан идентификатор запроса. Файл с обучающей выборкой содержит оценку релевантности, значения из диапазона [0, 4] (4 – «высокая релевантность», 0 – «нерелевантно»).

При нахождении оптимальных параметров моделей максимизировалась суммарная nDCG для всех запросов \textbf{Q} в обучающей выборке:

\begin{equation}
\label{eq:nDCG_error}
\mathrm{nDCG_{p}^{sum} = \sum_{q\in{Q}} \frac{DCG_{p}}{IDCG_{p}}},
\end{equation}

Для контроля качества находилась средняя nDCG для тестовой выборки.

Далее под линейной моделью понимается функция $f(w,x) = w*x^{T}$, где параметры $w$ подбираются так, чтобы уменьшить среднеквадратичную ошибку на обучающей выборке. Соответственно линейная модель не сравнивает зависимые переменные как модели, генерируемые mvr.sl, а предсказывает оценку ассессора.

На данном этапе вычислительного эксперимента предлагается сгенерировать с помощью mvr.sl несколько признаков, затем добавить их к уже имеющимся и оценить изменение качества линейной модели на тестовой выборке.

Для начала воспользуемся синтетическими данными. Для этого воспользуемся функцией Розенброка:
$$f(\mathbf{x}) = \sum_{i=1}^{N-1} \left[  (1-x_i)^2+ 100 (x_{i+1} - x_i^2 )^2 \right] \quad, \forall  x\in\mathbb{R}^N,$$ при $N=40$. Добавим к значениям $f(\mathbf{x})$ шум, равный 1\% от среднего значения $f(\mathbf{x})$, имеющий нормальное распределение. Добавим 10 шумовых переменных, имеющих нормальное распределение.

\begin{figure}[H]
\begin{center}
\subfloat{\includegraphics[width=0.5\textwidth]{15_synthetic50+13vars_QUALITY_BY_GEN_VARS_ADDED1.eps}}
\subfloat{\includegraphics[width=0.5\textwidth]{15_synthetic50+13vars_QUALITY_BY_GEN_VARS_ADDED2.eps}}
\end{center}
\caption{Изменение качества линейной модели при пошаговом добавление сгенерированных переменных.}
\end{figure}

\begin{figure}[H]
\begin{center}
\subfloat[50 исходных признаков]{\includegraphics[width=0.5\textwidth]{15_synthetic50+13vars_FLM_WITH_0GEN_VARS.eps}}
\subfloat[добавлен один сгенерированный признак]{\includegraphics[width=0.5\textwidth]{15_synthetic50+13vars_FLM_WITH_1GEN_VAR.eps}}//
\subfloat[добавлено два сгенерированных признака]{\includegraphics[width=0.5\textwidth]{15_synthetic50+13vars_FLM_WITH_2GEN_VARS.eps}}
\subfloat[добавлено три сгенерированных признака]{\includegraphics[width=0.5\textwidth]{15_synthetic50+13vars_FLM_WITH_3GEN_VARS.eps}}
\end{center}
\caption{Пошаговое добавление переменных при поиске линейной модели.}
\end{figure}

\begin{figure}[H]
\begin{center}
\subfloat{\includegraphics[width=0.5\textwidth]{16_synthetic2+0vars_QUALITY_POLYNOMIAL1.eps}}
\subfloat{\includegraphics[width=0.5\textwidth]{16_synthetic2+0vars_QUALITY_POLYNOMIAL2.eps}}
\end{center}
\caption{Изменение качества полиномиальной модели в зависимости от степени полинома.}
\end{figure}

\begin{figure}[H]
\begin{center}
\subfloat[Полином первой степени]{\includegraphics[width=0.5\textwidth]{16_synthetic2+0vars_QUALITY_POLYNOMIAL_POWER1.eps}}
\subfloat[Полином второй степени]{\includegraphics[width=0.5\textwidth]{16_synthetic2+0vars_QUALITY_POLYNOMIAL_POWER2.eps}}//
\subfloat[Полином третьей степени]{\includegraphics[width=0.5\textwidth]{16_synthetic2+0vars_QUALITY_POLYNOMIAL_POWER3.eps}}
\subfloat[Полином четвертой степени]{\includegraphics[width=0.5\textwidth]{16_synthetic2+0vars_QUALITY_POLYNOMIAL_POWER4.eps}}
\end{center}
\caption{Зависимость качества полиномиальной модели от количества переменных.}
\end{figure}

На графике ниже изображена нормированная среднеквадратичная ошибка для линейной модели в зависимости от числа использованных переменных (переменные добавлялись по одной таким образом, чтобы получившаяся модель давала наилучшее качество на обучающей выборке). Минимум ошибки на тестовой выборке достигается при 40 переменных и равен 0.1676. Эти переменные были использованы для порождения новых признаков. После добавления к имеющимся признакам 8 сгенерированных признаков, о которых написано ниже, минимум ошибки на тестовой выборке достигается при 38 переменных и равен 0.1139.

\begin{figure}[H]
\begin{center}
\subfloat[50 исходных признаков]{\includegraphics[width=0.5\textwidth]{13_synthetic40+10vars_FLM+0_bestOn40vars.eps}}
\subfloat[дополнительно 8 сгенерированных признаков]{\includegraphics[width=0.5\textwidth]{14_synthetic40+10vars_FLM+8_bestOn38vars.eps}}
\end{center}
\caption{Зависимость ошибки от количества признаков в линейной модели на обучающей и тестовой выборках.}
\end{figure}

С помощью mvr.sl были сгенерированы 8 признаков и добавлены к имеющимся 50. Два графика, описывающие качество и сложность генерируемых признаков приведены ниже.

\begin{figure}[H]
\begin{center}
\subfloat{\includegraphics[width=0.5\textwidth]{14_synthetic40+10vars_MAIN1_bestOn38vars.eps}}
\subfloat{\includegraphics[width=0.5\textwidth]{14_synthetic40+10vars_MAIN2_bestOn38vars.eps}}\\
\caption{Примеры порождаемых mvr.sl признаков.}
\end{center}
\end{figure}


Для линейной модели из 40 переменных, настраиваемой на обучающей выборке без порожденных признаков, nDCG на тестовой выборке составило 0.9329, а для линейной модели из 38 переменных, настраиваемой на обучающей выборке с порожденными признаками, nDCG составило 0.9618.

Теперь воспользуемся реальными данными Яндекса. На графике ниже изображена нормированная среднеквадратичная ошибка для линейной модели в зависимости от числа использованных переменных (переменные добавлялись по одной таким образом, чтобы получившаяся модель давала наилучшее качество на обучающей выборке). Минимум ошибки на тестовой выборке достигается при 15 переменных и равен 0.9129. Эти переменные были использованы для порождения новых признаков. После добавления к имеющимся признакам 7 сгенерированных признаков, о которых написано ниже, минимум ошибки на тестовой выборке достигается при 30 переменных и равен 0.8664.

\begin{figure}[H]
\begin{center}
\subfloat[245 исходных признаков]{\includegraphics[width=0.5\textwidth]{QualityDependenceOnNumberOfFeatures1.pdf}}
\subfloat[дополнительно 7 сгенерированных признаков]{\includegraphics[width=0.5\textwidth]{QualityDependenceOnNumberOfFeatures2.eps}}
\end{center}
\caption{Зависимость ошибки от количества признаков в линейной модели на обучающей и тестовой выборках. Синим цветом изображено качество на обучающей выборке, зеленым - на тестовой.}
\end{figure}

С помощью mvr.sl были сгенерированы 7 признаков и добавлены к имеющимся 245. Два графика, описывающие качество и сложность генерируемых признаков приведены ниже.

\begin{figure}[H]
\begin{center}
\subfloat{\includegraphics[width=0.5\textwidth]{generatedFeatureExample1.pdf}}
\subfloat{\includegraphics[width=0.5\textwidth]{generatedFeatureExample2.eps}}\\
\caption{Примеры порождаемых mvr.sl признаков. Зеленой линией обозначена сложность модели (число элементарных функций и признаков), деленная на 10. Качество моделей измеряется в nDCG. Нулю на вертикальной оси соответствует значение nDCG для линейной модели из 15 признаков, выбранных при построении линейной модели, единице соответствует nDCG=1. Красным цветом обозначены качество на 100 элементах выборки, использующихся для построения и максимизации nDCG, бирюзовым цветом обозначено качество на 3900 элементах выборки, использующееся для выбора лучших моделей для следующей итерации, синим цветом обозначено качество моделей на 4000 элементах тестовой выборки.}
\end{center}
\end{figure}


Для линейной модели из 15 переменных, настраиваемой на обучающей выборке без порожденных признаков, nDCG на тестовой выборке составило 0.8778, а для линейной модели из 30 переменных, настраиваемой на обучающей выборке с порожденными признаками, nDCG составило 0.8804.

%Таким образом добавление порожденных признаков к уже имеющимся улучшает качество nDCG линейной модели на тестовой выборке.

\subsection{Формат реальных данных}

Функции ранжирования присваивают документу \textbf{d} некоторое положительное значение в ответ на запрос \textbf{q}, состоящий из термов \textbf{w}. Классически в ранжировании документов используются следующие переменные: частота терма $t^\textbf{d}_\textbf{w}$ и частота документа $N_\textbf{w}$.


Известно, что нормализованные величины более эффективны в задачах ранжирования документов. Например, подобные относительные величины используются в языковой модели \cite{robertson2004simple}, в BM25 используется нормализация Okapi \cite{robertson2009probabilistic}. Для этой работы были выбраны величины, использующиеся в DFR и information-based models \cite{clinchant2010information}, а также в работе \cite{Goswami2014}.

\begin{table}[h!]
\caption{\label{tab:notations} Использующиеся обозначения}
\begin{tabular}{ll}
  \hline
  Обозначение & Определение \\
  \hline
  $t^\textbf{d}_\textbf{w}$ & Количество появлений терма \textbf{w} в документе \textbf{d}, частота терма \\
  $t^\textbf{q}_\textbf{w}$ & Количество появлений терма \textbf{w} в запросе \textbf{q} \\
  $x^\textbf{d}_\textbf{w}$ & Нормализованная частота терма \\
  $N_\textbf{w}$ & Количество документов в коллекции, содержащих \textbf{w}, частота документа \\
  $y_\textbf{w}$ & Нормализованная частота документа \\
  $N$ & Количество документов в коллекции \\
  $l_\textbf{d}$ & Длина документа \textbf{d} в количестве термов \\
  $l_{avg}$ & Средняя длина документа в коллекции \\
  \hline
\end{tabular}
\end{table}

%Введем следующие переменные:

\begin{itemize}
  \item Нормализованная частота терма $x^\textbf{d}_\textbf{w} = t^\textbf{d}_\textbf{w} log(1+c\frac{l_{avg}}{l_\textbf{d}})$,
      где $c\in{R}$ ~--- множитель. Для простоты далее вместо $x^\textbf{d}_\textbf{w}$ будем писать $x$
  \item Нормализованная частота документа $y_\textbf{w} = \frac{N_\textbf{w}}{N}$ (нужны ли объяснения?). Для простоты далее вместо $y_\textbf{w}$ будем писать $y$
  \item Константа $k\in{R}$
\end{itemize}

\bibliography{Guschin2014DocumentRetrieval}

\end{document} 